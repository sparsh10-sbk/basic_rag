# RAG Pipeline with FAISS and Llama via Ollama

This repository implements a **Retrieval-Augmented Generation (RAG)** pipeline using FAISS for vector search, HuggingFace for embeddings, and Llama (via Ollama) for generating responses. The pipeline is designed to index pharmaceutical JSON files, retrieve relevant content, and generate answers to user queries.

---

## Features

- **FAISS Vector Index**: Efficiently stores and retrieves embeddings.
- **HuggingFace Embeddings**: Generates embeddings using `all-MiniLM-L6-v2`.
- **RAG Workflow**: Combines information retrieval with response generation.
- **Ollama Llama**: Utilizes Llama (via Ollama API) for coherent response generation.

---


